# <i> LLmHub.dev </i> - Automatic LLM Routing for Maximizing performance and Minimizing costs 

## â†”ï¸ Best LLM on Every Prompt

LLmHUB is the ultimate API for efficiently routing prompts to the best Large Language Models (LLMs) based on performance, cost, and user preferences. Our intelligent router automatically selects the optimal model for each request, saving both time and money.

---

## ğŸŒŸ Features

- **Automatic Model Selection**: Routes prompts to the most suitable LLM based on cost, latency, and quality.
- **Multi-LLM Support**: Seamlessly integrates with top LLM providers like OpenAI, Anthropic, Mistral, and more.
- **Advanced Cache Prompting**: Our unique caching mechanism reduces redundant calls, improving efficiency and reducing costs.
- **API Key Management**: Securely generate and manage API keys for usage tracking and analytics.
- **Real-time Metrics**: Monitor API usage, token consumption, and costs via a detailed dashboard.
- **Scalability & Reliability**: Built to handle high loads with robust cloud infrastructure.

---

## ğŸ“ˆ API Key Management
LLmHUB allows users to generate and manage multiple API keys:

- **Create API Key**: Generate new API keys for different use cases.
- **Track Usage**: Monitor request logs and cost distribution.
- **Revoke Keys**: Delete or disable API keys as needed.

---

## ğŸ—ï¸ Contributing

We welcome contributions from the community! To contribute:

1. Fork the repo and create a new branch.
2. Implement changes and commit with clear messages.
3. Submit a pull request for review.

---

## ğŸ“§ Contact & Support
- Website: [https://llmhub.dev](https://llmhub.dev)
- Email: prateek@llmhub.dev
- Linkedin: [@llmhub](https://www.linkedin.com/company/llmhub/)

---

## ğŸ“œ License
LLmHUB is licensed under the MIT License. See `LICENSE` for details.

---

### Made with â¤ï¸ by LLmHUB Team




